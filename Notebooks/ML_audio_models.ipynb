{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eIsRBwKWXLAz"
   },
   "source": [
    "# Classic Audio ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kC3emANWie2b"
   },
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2krRG5X-ikK4"
   },
   "source": [
    "### Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9284,
     "status": "ok",
     "timestamp": 1687818942514,
     "user": {
      "displayName": "Iker Honorato",
      "userId": "11641306937370756080"
     },
     "user_tz": -120
    },
    "id": "T5ta7rGKaN5k",
    "outputId": "9ee912c9-ae58-4f6c-aefc-b2d8ae5a3563"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting iterative-stratification\n",
      "  Downloading iterative_stratification-0.1.7-py3-none-any.whl (8.5 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from iterative-stratification) (1.22.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from iterative-stratification) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from iterative-stratification) (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->iterative-stratification) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->iterative-stratification) (3.1.0)\n",
      "Installing collected packages: iterative-stratification\n",
      "Successfully installed iterative-stratification-0.1.7\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.0.post2)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.0)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.22.4)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
      "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.56.4)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: pooch<1.7,>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.6.0)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.5)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.6.3)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.2)\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.5)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.39.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (67.7.2)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa) (23.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa) (2.27.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (3.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install iterative-stratification\n",
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXxxxQuUimtB"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q5MM2IzIC5Om"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report,f1_score,roc_auc_score,recall_score\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "from sklearn.utils import resample\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import librosa\n",
    "import warnings\n",
    "\n",
    "from google.colab import drive\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "warnings.simplefilter(action='ignore', category=ConvergenceWarning)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 203884,
     "status": "ok",
     "timestamp": 1687819148071,
     "user": {
      "displayName": "Iker Honorato",
      "userId": "11641306937370756080"
     },
     "user_tz": -120
    },
    "id": "mFGhFWC-amoP",
    "outputId": "8ac32733-28fa-4183-cf5b-e658e6eacec5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2CxGwibiw9R"
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIPwdIlIIcVH"
   },
   "source": [
    "##### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rdqqk0t5Il1a"
   },
   "outputs": [],
   "source": [
    "def inverse_frequency(df):\n",
    "    neg, pos = np.bincount(df[\"PHQ8_Binary\"])\n",
    "    total = neg + pos\n",
    "    print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "        total, pos, 100 * pos / total))\n",
    "\n",
    "    weight_for_0 = (1 / (neg / total))\n",
    "    weight_for_1 = (1 / (pos / total))\n",
    "\n",
    "    class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "  #initial_bias = np.log([pos/neg])\n",
    "\n",
    "    return class_weight\n",
    "\n",
    "def get_audio_waves(data):\n",
    "    audio_path = \"/content/gdrive/MyDrive/daiwoz/audios/\"\n",
    "    waves = {}\n",
    "    for id_ in tqdm(data.patient_id.unique()):\n",
    "        audio, sr = librosa.load(f\"{audio_path}{id_}_AUDIO.wav\",sr=None)\n",
    "        waves.setdefault(id_,(audio,sr))\n",
    "    return waves\n",
    "\n",
    "def random_oversample(df,seed):\n",
    "    # Separate the data based on class (assuming 'label' is the class column)\n",
    "    # with 1 being the positive (minority) class\n",
    "    df_minority = df[df['PHQ8_Binary'] == 1]\n",
    "    df_majority = df[df['PHQ8_Binary'] == 0]\n",
    "\n",
    "    # Perform oversampling on the minority class\n",
    "    df_minority_oversampled = resample(df_minority,\n",
    "                                      replace=True, # sample with replacement\n",
    "                                      n_samples=int(len(df_majority)*0.95), # match number in majority class\n",
    "                                      random_state=seed) # reproducible results\n",
    "\n",
    "    # Combine the majority class with the oversampled minority class\n",
    "    df_oversampled = pd.concat([df_majority, df_minority_oversampled])\n",
    "\n",
    "    return df_oversampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "US4FRbeljapf"
   },
   "source": [
    "##### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5mZGF1-baN5o"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "def extract_features(audio, sample_rate):\n",
    "    # 1. RMS Energy for loudness approximation\n",
    "    rms = np.mean(librosa.feature.rms(y=audio))\n",
    "    # 2. MFCCs\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40).T\n",
    "    # 3. Pitch\n",
    "    pitches, magnitudes = librosa.piptrack(y=audio, sr=sample_rate)\n",
    "    pitch = np.mean(pitches)\n",
    "    return rms, mfccs, pitch\n",
    "\n",
    "\n",
    "def preprocess(dataset, waveform_dict):\n",
    "    rms_values = []\n",
    "    mfccs_values = []\n",
    "    pitch_values = []\n",
    "\n",
    "    for index, row in dataset.iterrows():\n",
    "        id_ = row['patient_id']\n",
    "        start_time = row['start_time']\n",
    "        end_time = row['end_time']\n",
    "\n",
    "        # Get the corresponding waveform and trim it\n",
    "        waveform,sample_rate = waveform_dict[id_]\n",
    "        start_sample = int(start_time * sample_rate)\n",
    "        end_sample = int(end_time * sample_rate)\n",
    "        trimmed_waveform = waveform[start_sample:end_sample]\n",
    "\n",
    "        # Extract features\n",
    "        rms, mfccs, pitch = extract_features(trimmed_waveform, sample_rate)\n",
    "\n",
    "        # Append the results\n",
    "        rms_values.append(rms)\n",
    "        mfccs_values.append(np.mean(mfccs, axis=0))  # Taking the mean across time\n",
    "        pitch_values.append(pitch)\n",
    "\n",
    "    # Create new columns in the dataset\n",
    "    dataset['rms'] = rms_values\n",
    "    dataset['pitch'] = pitch_values\n",
    "\n",
    "    # Expand MFCCs into their own columns\n",
    "    mfccs_df = pd.DataFrame(mfccs_values, columns=[f'mfcc_{i}' for i in range(mfccs_values[0].shape[0])])\n",
    "    dataset = pd.concat([dataset.reset_index(drop=True), mfccs_df.reset_index(drop=True)],axis=1)\n",
    "\n",
    "    return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JMZLkSblaN5o"
   },
   "source": [
    "### Splitting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "txyilp7RaN5p"
   },
   "outputs": [],
   "source": [
    "def split_dataset(df, test_size=0.15, val_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "  Function that splits a df taking in consideration balancing o Gender, PHQ and length of intervention.\n",
    "\n",
    "  Params\n",
    "  ---\n",
    "    -df: The data to split\n",
    "    -test_size: the size of the test set\n",
    "    -val_size: the size of the validation set out of the remaining set after extracting the test set.\n",
    "    -random_state: The seed, for reproducibility\n",
    "\n",
    "  Returns\n",
    "  ---\n",
    "    - The same dataframe with a column name 'split' that indicates where each data point corresponds\n",
    "\n",
    "  \"\"\"\n",
    "    # Ensure the 'gender' column is numerical\n",
    "    if df['Gender'].dtype == 'object':\n",
    "        df['Gender'] = df['Gender'].astype('category').cat.codes\n",
    "\n",
    "    # Combine the 'gender' and 'label' columns into a new 2D array\n",
    "    y = df[['Gender', 'PHQ8_Binary']].values\n",
    "\n",
    "\n",
    "    try:\n",
    "      # Split the DataFrame into three equal parts representing short, medium, and long texts\n",
    "        labels=['short', 'medium', 'long']\n",
    "        df['text_length_category'] = pd.qcut(df['word_count'], 3, labels=labels)\n",
    "    except:\n",
    "        labels=['short', 'long']\n",
    "        # Split into 'short' and 'long' based on the median\n",
    "        median = df['word_count'].median()\n",
    "        df['text_length_category'] = np.where(df['word_count'] <= median, 'short', 'long')\n",
    "\n",
    "\n",
    "    df_train = pd.DataFrame()\n",
    "    df_test = pd.DataFrame()\n",
    "\n",
    "\n",
    "    df_columns_to_drop = ['patient_id', 'intervention', 'question', 'start_time', 'end_time',\n",
    "       'question_text', 'Gender', 'PHQ8_Score', 'PHQ8_Binary', 'split',\n",
    "       'word_count','text_length_category']\n",
    "\n",
    "    # Loop over each category\n",
    "    for category in labels:\n",
    "        df_temp = df[df['text_length_category'] == category]\n",
    "\n",
    "        # Create the initial splitter\n",
    "        initial_split = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
    "\n",
    "        # Split out the test set\n",
    "        for other_index, test_index in initial_split.split(df_temp, df_temp[['Gender', 'PHQ8_Binary']].values):\n",
    "            df_train_, df_test_ = df_temp.iloc[other_index], df_temp.iloc[test_index]\n",
    "\n",
    "\n",
    "        df_train = pd.concat([df_train.copy(),df_train_])\n",
    "        df_test = pd.concat([df_test.copy(),df_test_])\n",
    "\n",
    "    df_train = df_train.dropna()\n",
    "    df_test = df_test.dropna()\n",
    "\n",
    "    y_train,x_train = df_train[\"PHQ8_Binary\"], df_train.drop(df_columns_to_drop,axis=1)\n",
    "    y_test,x_test = df_test[\"PHQ8_Binary\"], df_test.drop(df_columns_to_drop,axis=1)\n",
    "\n",
    "    return x_train,y_train,x_test,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lewe3PuU57ik"
   },
   "source": [
    "#### Define the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VUHWcSfMF0bK"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/content/gdrive/MyDrive/daiwoz/best_questions.csv\",index_col=0).rename(columns={\"id\":\"patient_id\"})\n",
    "data[\"question\"] = data.question + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 321141,
     "status": "ok",
     "timestamp": 1687819471976,
     "user": {
      "displayName": "Iker Honorato",
      "userId": "11641306937370756080"
     },
     "user_tz": -120
    },
    "id": "1o0XbJnyaN5q",
    "outputId": "5f35fd1f-5e32-4f22-83d1-19ef2429651b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 186/186 [05:20<00:00,  1.72s/it]\n"
     ]
    }
   ],
   "source": [
    "waves = get_audio_waves(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpoESRG3AaE-"
   },
   "source": [
    "#### Define the param_grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bLfHuAhEaN5r"
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('Logistic Regression', LogisticRegression(class_weight='balanced'), {\n",
    "        'classifier__C': [0.1, 1, 5, 10],\n",
    "        'classifier__penalty': ['none', 'l2']\n",
    "    }),\n",
    "    ('Random Forest', RandomForestClassifier(class_weight='balanced'), {\n",
    "        'classifier__n_estimators': [10, 100, 200, 300],\n",
    "        'classifier__max_depth': [None, 5, 10],\n",
    "        'classifier__criterion': ['gini', 'entropy']\n",
    "    }),\n",
    "    ('Support Vector Machine', SVC(class_weight='balanced', probability=True), {\n",
    "        'classifier__C': [0.1, 1, 5, 10],\n",
    "        'classifier__gamma': ['scale', 'auto'],\n",
    "        'classifier__kernel': ['rbf', 'linear']\n",
    "    })\n",
    "]\n",
    "\n",
    "# Define the pipeline for text classification\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', StandardScaler()),  # Convert text into numerical features #Feature selector sencillo\n",
    "    ('classifier', None)  # Placeholder for the classifier\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z2WOGRbFbGYC"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "def train_questions(data, waveforms,models, pipeline):\n",
    "    # Train and evaluate each model\n",
    "\n",
    "    results_df = pd.DataFrame(columns=['Question','Best Model','Train F1','Train Recall','Train AUC','Test F1','Test Recall','Test AUC'])\n",
    "\n",
    "    for question in tqdm(data.question.unique()):\n",
    "        best_model = None\n",
    "\n",
    "        best_f1 = 0.0\n",
    "        best_recall = 0.0\n",
    "        best_auc = 0.0\n",
    "\n",
    "        best_f1_mean = 0.0\n",
    "        best_recall_mean = 0.0\n",
    "        best_auc_mean = 0.0\n",
    "\n",
    "        question_data = preprocess(data.loc[data.question==question],waveforms)\n",
    "\n",
    "        kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "        x_train, y_train, x_test, y_test = split_dataset(question_data)\n",
    "\n",
    "        for model_name, model, param_grid in models:\n",
    "            pipeline.set_params(classifier=model)\n",
    "            grid_search = GridSearchCV(pipeline, param_grid, scoring=[\"f1\",\"roc_auc\",\"recall\"], cv=kfold, n_jobs=-1, refit='f1')\n",
    "            grid_search.fit(x_train, y_train)\n",
    "\n",
    "            y_pred = grid_search.predict(x_test)\n",
    "\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            recall = recall_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "            if f1 > best_f1:\n",
    "\n",
    "                best_model = model_name\n",
    "\n",
    "                best_f1 = f1\n",
    "                best_recall = recall\n",
    "                best_auc = auc\n",
    "\n",
    "                best_f1_mean = grid_search.best_score_\n",
    "                best_recall_mean = grid_search.cv_results_['mean_test_recall'][grid_search.best_index_]\n",
    "                best_auc_mean = grid_search.cv_results_['mean_test_roc_auc'][grid_search.best_index_]\n",
    "\n",
    "        results_df = results_df.append({\n",
    "            'Question': question,\n",
    "            'Best Model': best_model,\n",
    "            'Train F1': best_f1_mean,\n",
    "            'Train Recall': best_recall_mean,\n",
    "            'Train AUC': best_auc_mean,\n",
    "            'Test F1': best_f1,\n",
    "            'Test Recall': best_recall,\n",
    "            'Test AUC': best_auc\n",
    "        }, ignore_index=True)\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 370086,
     "status": "ok",
     "timestamp": 1687703786945,
     "user": {
      "displayName": "Iker Honorato",
      "userId": "11641306937370756080"
     },
     "user_tz": -120
    },
    "id": "sg7WvhFcaN5r",
    "outputId": "7c6f1bd0-2b34-4b49-b120-7ed41ac44e23"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [06:09<00:00, 28.45s/it]\n"
     ]
    }
   ],
   "source": [
    "results_df = train_questions(data,waves,models,pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 865
    },
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1687703786946,
     "user": {
      "displayName": "Iker Honorato",
      "userId": "11641306937370756080"
     },
     "user_tz": -120
    },
    "id": "3UV_aCcXaN5s",
    "outputId": "c46c6309-71bb-4a98-bc83-a8fde353f951"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-02bbc4c0-40d3-4f05-b3e8-3d8cde214cbc\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>Best Model</th>\n",
       "      <th>Train F1</th>\n",
       "      <th>Train Recall</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Test F1</th>\n",
       "      <th>Test Recall</th>\n",
       "      <th>Test AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.447028</td>\n",
       "      <td>0.531944</td>\n",
       "      <td>0.568904</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.598214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.390119</td>\n",
       "      <td>0.445833</td>\n",
       "      <td>0.526830</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.392554</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.536471</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.469952</td>\n",
       "      <td>0.585714</td>\n",
       "      <td>0.620542</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.274604</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.582540</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.758333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.451876</td>\n",
       "      <td>0.600733</td>\n",
       "      <td>0.624154</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.530075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.383065</td>\n",
       "      <td>0.419048</td>\n",
       "      <td>0.487848</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.618421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.367468</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.553540</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.582707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.446951</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.472631</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.322876</td>\n",
       "      <td>0.387500</td>\n",
       "      <td>0.440357</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.407608</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.525637</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.443863</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.603687</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.690476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.521886</td>\n",
       "      <td>0.593434</td>\n",
       "      <td>0.566761</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.484848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02bbc4c0-40d3-4f05-b3e8-3d8cde214cbc')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-02bbc4c0-40d3-4f05-b3e8-3d8cde214cbc button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-02bbc4c0-40d3-4f05-b3e8-3d8cde214cbc');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   question              Best Model  Train F1  Train Recall  Train AUC  \\\n",
       "0         1  Support Vector Machine  0.447028      0.531944   0.568904   \n",
       "1         2  Support Vector Machine  0.390119      0.445833   0.526830   \n",
       "2         3  Support Vector Machine  0.392554      0.466667   0.536471   \n",
       "3         5  Support Vector Machine  0.469952      0.585714   0.620542   \n",
       "4         6           Random Forest  0.274604      0.222222   0.582540   \n",
       "5         7     Logistic Regression  0.451876      0.600733   0.624154   \n",
       "6         8     Logistic Regression  0.383065      0.419048   0.487848   \n",
       "7         9     Logistic Regression  0.367468      0.410256   0.553540   \n",
       "8        11  Support Vector Machine  0.446951      1.000000   0.472631   \n",
       "9        12  Support Vector Machine  0.322876      0.387500   0.440357   \n",
       "10        4     Logistic Regression  0.407608      0.452381   0.525637   \n",
       "11       10  Support Vector Machine  0.443863      0.547619   0.603687   \n",
       "12       13     Logistic Regression  0.521886      0.593434   0.566761   \n",
       "\n",
       "     Test F1  Test Recall  Test AUC  \n",
       "0   0.454545     0.625000  0.598214  \n",
       "1   0.480000     0.750000  0.600000  \n",
       "2   0.571429     0.666667  0.666667  \n",
       "3   0.500000     0.714286  0.666667  \n",
       "4   0.615385     0.666667  0.758333  \n",
       "5   0.352941     0.428571  0.530075  \n",
       "6   0.470588     0.500000  0.618421  \n",
       "7   0.400000     0.428571  0.582707  \n",
       "8   0.451613     1.000000  0.500000  \n",
       "9   0.526316     0.625000  0.662500  \n",
       "10  0.444444     0.500000  0.600000  \n",
       "11  0.555556     0.714286  0.690476  \n",
       "12  0.333333     0.333333  0.484848  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.rename(columns={\"Question\":\"question\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "glpN8N2SBqdv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
